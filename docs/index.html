<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>PyTorch C++ Cheatsheet</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=4f649999" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=cb25574f" />
    <script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="pytorch-c-cheatsheet">
<h1>PyTorch C++ Cheatsheet<a class="headerlink" href="#pytorch-c-cheatsheet" title="Link to this heading">ยง</a></h1>
<section id="tensor-creation">
<h2>Tensor creation<a class="headerlink" href="#tensor-creation" title="Link to this heading">ยง</a></h2>
<blockquote>
<div><p>See also [tensor_creation.html](<a class="reference external" href="https://pytorch.org/cppdocs/notes/tensor_creation.html">https://pytorch.org/cppdocs/notes/tensor_creation.html</a>)</p>
<p>Factory arguments order = <cite>(function-specific, sizes, options)</cite> (except for torch::full)</p>
</div></blockquote>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">x</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">opts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">TensorOptions</span><span class="p">()</span>
<span class="w">    </span><span class="p">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">)</span><span class="w">     </span><span class="c1">// kUInt8, kInt8, kInt16, kInt32, kInt64, kFloat32, or kFloat64</span>
<span class="w">    </span><span class="p">.</span><span class="n">layout</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kStrided</span><span class="p">)</span><span class="w">    </span><span class="c1">// kStrided, or kSparse</span>
<span class="w">    </span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kCPU</span><span class="p">)</span><span class="w">        </span><span class="c1">// kCPU, or kCUDA</span>
<span class="w">    </span><span class="p">.</span><span class="n">requires_grad</span><span class="p">(</span><span class="nb">false</span><span class="p">);</span><span class="w">      </span><span class="c1">// true, or false</span>

<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">opts</span><span class="p">);</span><span class="w">          </span><span class="c1">// 0</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">ones</span><span class="p">(</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">opts</span><span class="p">);</span><span class="w">          </span><span class="c1">// 1</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">empty</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">opts</span><span class="p">);</span><span class="w">          </span><span class="c1">// uninitialized</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">full</span><span class="p">(</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="mf">3.14f</span><span class="p">,</span><span class="w"> </span><span class="n">opts</span><span class="p">);</span><span class="w">   </span><span class="c1">// single value (warning: args order)</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">eye</span><span class="p">(</span><span class="w">  </span><span class="mi">5</span><span class="p">,</span><span class="w">     </span><span class="n">opts</span><span class="p">);</span><span class="w">          </span><span class="c1">// identity matrix (square)</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">eye</span><span class="p">(</span><span class="w">  </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w">  </span><span class="n">opts</span><span class="p">);</span><span class="w">          </span><span class="c1">// identity matrix (rectangular)</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">rand</span><span class="p">(</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">opts</span><span class="p">);</span><span class="w">          </span><span class="c1">// uniform distribution on [0, 1)</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">opts</span><span class="p">);</span><span class="w">          </span><span class="c1">// unit normal distribution</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">opts</span><span class="p">);</span><span class="w">    </span><span class="c1">// random integers (low=0)</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">opts</span><span class="p">);</span><span class="w"> </span><span class="c1">// random integers in (low,high)</span>

<span class="c1">// multiple chained short options</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat64</span><span class="p">).</span><span class="n">device</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kCPU</span><span class="p">));</span>

<span class="c1">// only one option (directly given as parameter)</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat64</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="tensor-shape">
<h2>Tensor shape<a class="headerlink" href="#tensor-shape" title="Link to this heading">ยง</a></h2>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">const</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">});</span>

<span class="c1">// dimension</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">dim</span><span class="p">();</span>
<span class="n">assert</span><span class="p">(</span><span class="n">dim</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">3</span><span class="p">);</span>

<span class="c1">// sizes</span>
<span class="k">const</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">long</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">sizes</span><span class="p">();</span>
<span class="n">assert</span><span class="p">(</span><span class="n">sizes</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">}));</span><span class="w"> </span><span class="c1">// comparable to std::vector&lt;int64_t&gt;</span>

<span class="c1">// single size</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span><span class="w"> </span><span class="c1">// same as x.sizes()[1]</span>
<span class="n">assert</span><span class="p">(</span><span class="n">size1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="tensor-data-type">
<h2>Tensor data type<a class="headerlink" href="#tensor-data-type" title="Link to this heading">ยง</a></h2>
<blockquote>
<div><p>types are static constant of type <cite>torch::ScalarType</cite></p>
</div></blockquote>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">type_float32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">;</span><span class="w"> </span><span class="c1">// type = c10::ScalarType</span>

<span class="c1">// map torch to c++ type</span>
<span class="k">static_assert</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">is_same_v</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">ScalarTypeToCPPType</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="o">&gt;::</span><span class="n">type</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">&gt;</span><span class="p">);</span>
<span class="k">static_assert</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">is_same_v</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">ScalarTypeToCPPType</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat64</span><span class="o">&gt;::</span><span class="n">type</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="o">&gt;</span><span class="p">);</span>
<span class="k">static_assert</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">is_same_v</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">ScalarTypeToCPPType</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">kInt32</span><span class="o">&gt;::</span><span class="n">type</span><span class="p">,</span><span class="w">   </span><span class="kt">int</span><span class="o">&gt;</span><span class="p">);</span>

<span class="c1">// map c++ to torch type (Cpp not CPP)</span>
<span class="k">static_assert</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">CppTypeToScalarType</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;::</span><span class="n">value</span><span class="w">  </span><span class="o">==</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">);</span>
<span class="k">static_assert</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">CppTypeToScalarType</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;::</span><span class="n">value</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat64</span><span class="p">);</span>
<span class="k">static_assert</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">CppTypeToScalarType</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">value</span><span class="w">    </span><span class="o">==</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kInt32</span><span class="p">);</span>

<span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">toString</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"> </span><span class="c1">// print &#39;Float&#39;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">elementSize</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">);</span><span class="w">   </span><span class="c1">// dynamic equivalent to sizeof(float)</span>
<span class="n">assert</span><span class="p">(</span><span class="n">bytes</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span><span class="w"> </span><span class="c1">// 4 bytes = 32 bits</span>

<span class="n">assert</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">isIntegralType</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">,</span><span class="w"> </span><span class="cm">/*includeBool=*/</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="n">assert</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">isFloatingType</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="tensor-efficient-accessors">
<h2>Tensor (efficient) accessors<a class="headerlink" href="#tensor-efficient-accessors" title="Link to this heading">ยง</a></h2>
<blockquote>
<div><p>See [tensor_basics.html](<a class="reference external" href="https://pytorch.org/cppdocs/notes/tensor_basics.html#efficient-access-to-tensor-elements">https://pytorch.org/cppdocs/notes/tensor_basics.html#efficient-access-to-tensor-elements</a>)
Type and dimension must be known at compile-time</p>
</div></blockquote>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">({</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">);</span>

<span class="c1">// cpu</span>
<span class="k">auto</span><span class="w"> </span><span class="n">accessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">accessor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span><span class="p">();</span><span class="w"> </span><span class="c1">// dim = 3</span>
<span class="n">accessor</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">3.14f</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="tensor-inefficient-indexing">
<h2>Tensor (inefficient) indexing<a class="headerlink" href="#tensor-inefficient-indexing" title="Link to this heading">ยง</a></h2>
<blockquote>
<div><p>See [tensor_indexing.html](<a class="reference external" href="https://pytorch.org/cppdocs/notes/tensor_indexing.html">https://pytorch.org/cppdocs/notes/tensor_indexing.html</a>)</p>
</div></blockquote>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">rand</span><span class="p">({</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">});</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">index</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">}).</span><span class="n">sizes</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="tensor-memory-and-device">
<h2>Tensor memory and device<a class="headerlink" href="#tensor-memory-and-device" title="Link to this heading">ยง</a></h2>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">({</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">);</span>

<span class="c1">// memory ptr</span>
<span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">raw_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">data_ptr</span><span class="p">();</span>
<span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">typed_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">();</span>

<span class="c1">// device</span>
<span class="n">assert</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">is_cpu</span><span class="p">());</span>
<span class="n">assert</span><span class="p">(</span><span class="k">not</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">is_cuda</span><span class="p">());</span>

<span class="n">torch</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">();</span>
<span class="n">assert</span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">is_cpu</span><span class="p">());</span>
<span class="n">assert</span><span class="p">(</span><span class="k">not</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">is_cuda</span><span class="p">());</span>

<span class="c1">// memory</span>
<span class="n">assert</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">is_contiguous</span><span class="p">());</span>
<span class="n">torch</span><span class="o">::</span><span class="n">Layout</span><span class="w"> </span><span class="n">layout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">layout</span><span class="p">();</span>
<span class="kt">long</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="kt">long</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="kt">long</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
<span class="n">assert</span><span class="p">(</span><span class="n">stride0</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">3</span><span class="o">*</span><span class="mi">2</span><span class="p">);</span>
<span class="n">assert</span><span class="p">(</span><span class="n">stride1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">2</span><span class="p">);</span>
<span class="n">assert</span><span class="p">(</span><span class="n">stride2</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="dispatching">
<h2>Dispatching<a class="headerlink" href="#dispatching" title="Link to this heading">ยง</a></h2>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">rand</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">);</span>
<span class="n">AT_DISPATCH_ALL_TYPES</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">scalar_type</span><span class="p">(),</span><span class="w"> </span><span class="s">&quot;unique_name&quot;</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="o">&amp;</span><span class="p">]</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">scalar_t</span><span class="w"> </span><span class="n">val</span><span class="p">;</span>
<span class="p">});</span>
</pre></div>
</div>
</section>
<section id="tensor-creation-from-raw-data">
<h2>Tensor creation from raw data<a class="headerlink" href="#tensor-creation-from-raw-data" title="Link to this heading">ยง</a></h2>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">rows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="kt">int</span><span class="w"> </span><span class="n">cols</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span>
<span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">raw_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">rows</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">cols</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">rows</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">cols</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span>
<span class="w">    </span><span class="n">raw_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="c1">// data = [0,  1,  2,</span>
<span class="c1">//         3,  4,  5,</span>
<span class="c1">//         6,  7,  8,</span>
<span class="c1">//         9, 10, 11]</span>
<span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&gt;</span><span class="w"> </span><span class="n">deleter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[](</span><span class="kt">void</span><span class="o">*</span><span class="p">){</span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;delete!&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;};</span>
<span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">from_blob</span><span class="p">(</span><span class="n">raw_data</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">rows</span><span class="p">,</span><span class="w"> </span><span class="n">cols</span><span class="p">},</span><span class="w"> </span><span class="n">deleter</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kInt32</span><span class="p">));</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="c1">// end of scope prints &#39;delete!&#39;</span>
</pre></div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="#">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">PyTorch C++ Cheatsheet</a><ul>
<li><a class="reference internal" href="#tensor-creation">Tensor creation</a></li>
<li><a class="reference internal" href="#tensor-shape">Tensor shape</a></li>
<li><a class="reference internal" href="#tensor-data-type">Tensor data type</a></li>
<li><a class="reference internal" href="#tensor-efficient-accessors">Tensor (efficient) accessors</a></li>
<li><a class="reference internal" href="#tensor-inefficient-indexing">Tensor (inefficient) indexing</a></li>
<li><a class="reference internal" href="#tensor-memory-and-device">Tensor memory and device</a></li>
<li><a class="reference internal" href="#dispatching">Dispatching</a></li>
<li><a class="reference internal" href="#tensor-creation-from-raw-data">Tensor creation from raw data</a></li>
</ul>
</li>
</ul>

  </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2025, Thibault Lejemble.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>